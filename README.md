# trust-and-teach


## contract and ui

after modifying a contract

```
cd trust-and-teach-cartesi
docker compose -f docker-compose.yml -f docker-compose.override.yml down -v ; docker image rm trust-and-teach-cartesi-contracts
docker buildx bake -f docker-bake.hcl -f docker-bake.override.hcl --load && docker compose -f docker-compose.yml -f docker-compose.override.yml up
solc --abi --optimize --base-path . --include-path node_modules/ ../trust-and-teach-cartesi/contracts/src/localhost/trust-and-teach.sol -o src/contract_abi/
cd src/contract_abi/
mv TrustAndTeach.abi TrustAndTeach.json
```


**milestone: splitting a payload into multiple vouchers**
works:
- split LLM response into multiple vouchers
- automated testing for multiple vouchers
(details below)
Problems I'm currently working on:
- even though 200+ random :alpha: + space character strings work, the llama2.c inference doesn't post a notice.
Todo: 
- run on test net
- write docs
- simple ui

the log of the dbf2a0e9d4c3814737987f9cfb05ee3948a42e47
https://github.com/kirilligum/coin-toss/raw/ic08/runs_history/2023-12-21T19:01:39+00:00/2023-12-21T19:01:39+00:00__ic08/commit.log
shows:
- submit an instruction to an LLM inside cartesi
- notice shows responses
- we see a list of vouchers, where each voucher is 512 characters of the response
- vouchers get executed
- we see vouchers on-chain
- we give human feedback on the best response on-chain



# Trust-and-Teach AI DApp

<!--START_SECTION:update_image-->
<img src="diagrams/usersequence.mmd.svg" width="500">
<!--END_SECTION:update_image-->

## Motivation

This DApp is reinforcement learning with human feedback (RLHF) on-chain, leverging on-chain trust, scalability, transparensy, and reputation.
Higher accuracy for specific application as well as a practical interface, such as chat, of large language models (LLMs) comes from supervised fine-tunning (SFT) and RLHF.
In RLHF, a human ranks responses from the same prompt of an already fine-tuned model. 
These ranks are used to fine-tune the LLM.
In this project we get 2 inferences from on-chain LLM and allow the users to rank which of the two responses is better.
The next step would be to fine-tune the model using the dataset generated by this project.

## How it works
The LLM runs as an oprimistic rollup onto EVM chain.
Cartesi VM allows running linux applications, in our case, we run llama2.c with stories15m model.
The Cartesi Rollup infrastructure optimistically executes the transitions between the states of the Cartesi VM.
After finishing running the LLM, Cartesi creates vouchers. 
These vouchers allow to validate and post the result of running the LLM on to the EVM; for that the vouchers need to be executed as an EVM transaction.

## User flow
1. Enter the prompt and run 2 LLM **inferences** by clicking "Generate" button and signing the transaction.
    1. (optionally) enter the total number of tokens that llm will work with = tokens you entered + tokens that LLM will generate
1. When LLM is done, you will see "Off-chain" reponses in the table. You will need to wait for the voucher proofs to be ready. Once the proofs are ready, you can **post** the LLM responses on to the chain by clicking "Post 0" and "Post 1".
1. Now you can **rank** the responses. If you like the order of the responses, you can click "Confirm" if you prefer to switch them, you can click "Switch".
1. When you looped over the previous steps enough times to have a dataset, you can download the dataset as a TSV or JSON. Next you can do the RLHF fine-tuning of the model using other projects.

## Building

To build the application, run the following command:

```shell
docker buildx bake -f docker-bake.hcl -f docker-bake.override.hcl --load
```

## Running

To start the application, execute the following command:

```shell
docker compose -f docker-compose.yml -f docker-compose.override.yml up
```

The application can afterwards be shut down with the following command:

```shell
docker compose -f docker-compose.yml -f docker-compose.override.yml down -v
```

### Deploying DApps

Deploying a new Cartesi DApp to a blockchain requires creating a smart contract on that network, as well as running a validator node for the DApp.

The first step is to build the DApp's back-end machine, which will produce a hash that serves as a unique identifier.

```shell
docker buildx bake -f docker-bake.hcl -f docker-bake.override.hcl machine --load --set *.args.NETWORK=sepolia
```

Once the machine docker image is ready, we can use it to deploy a corresponding Rollups smart contract.
This requires you to specify the account and RPC gateway to use when submitting the deploy transaction on the target network, which can be done by defining the following environment variables:

```shell
export MNEMONIC=<user sequence of twelve words>
export RPC_URL=<https://your.rpc.gateway>
```

For example, to deploy to the Sepolia testnet using an Alchemy RPC node, you could execute:

```shell
export MNEMONIC=<user sequence of twelve words>
export RPC_URL=https://eth-sepolia.alchemyapi.io/v2/<USER_KEY>
```

With that in place, you can submit a deploy transaction to the Cartesi DApp Factory contract on the target network by executing the following command:

```shell
DAPP_NAME="trust-and-teach" docker compose --env-file env.<network> -f deploy-testnet.yml up
```

Here, `env.<network>` specifies general parameters for the target network, like its name and chain ID. In the case of Sepolia, the command would be:

```shell
DAPP_NAME="trust-and-teach" docker compose --env-file env.sepolia -f deploy-testnet.yml up
```

This will create a file at `deployments/<network>/trust-and-teach.json` with the deployed contract's address.
Once the command finishes, it is advisable to stop the docker compose and remove the volumes created when executing it.

```shell
DAPP_NAME="trust-and-teach" docker compose --env-file env.<network> -f deploy-testnet.yml down -v
```

After that, a corresponding Cartesi Validator Node must also be instantiated in order to interact with the deployed smart contract on the target network and handle the back-end logic of the DApp.
Aside from the environment variables defined before, the node will also need a secure websocket endpoint for the RPC gateway (WSS URL).

For example, for Sepolia and Alchemy, you would set the following additional variable:

```shell
export WSS_URL=wss://eth-sepolia.alchemyapi.io/v2/<USER_KEY>
```

Then, the node itself can be started by running a docker compose as follows:

```shell
DAPP_NAME="trust-and-teach" docker compose --env-file env.<network> -f docker-compose-testnet.yml up
```

Alternatively, you can also run the node on host mode by executing:

```shell
DAPP_NAME="trust-and-teach" docker compose --env-file env.<network> -f docker-compose-testnet.yml -f docker-compose-host-testnet.yml up
```

## Running the back-end in host mode

When developing an application, it is often important to easily test and debug it. For that matter, it is possible to run the Cartesi Rollups environment in [host mode](https://github.com/cartesi/rollups-examples/tree/main/README.md#host-mode), so that the DApp's back-end can be executed directly on the host machine, allowing it to be debugged using regular development tools such as an IDE.

The host environment can be executed with the following command:

```shell
docker compose -f docker-compose.yml -f docker-compose.override.yml -f docker-compose-host.yml up
```

This DApp's back-end is written in Python, so to run it in your machine you need to have `python3` installed.

In order to start the back-end, run the following commands in a dedicated terminal:

```shell
python3 -m venv .venv
. .venv/bin/activate
pip install -r requirements.txt
ROLLUP_HTTP_SERVER_URL="http://127.0.0.1:5004" python3 trust-and-teach.py
```

The final command will effectively run the back-end and send corresponding outputs to port `5004`.
It can optionally be configured in an IDE to allow interactive debugging using features like breakpoints.

You can also use a tool like [entr](https://eradman.com/entrproject/) to restart the back-end automatically when the code changes. For example:

```shell
ls *.py | ROLLUP_HTTP_SERVER_URL="http://127.0.0.1:5004" entr -r python3 trust-and-teach.py
```

After the back-end successfully starts, it should print an output like the following:

```log
INFO:__main__:HTTP rollup_server url is http://127.0.0.1:5004
INFO:__main__:Sending finish
```

After that, you can interact with the application normally [as explained above](#interacting-with-the-application).


## Interacting with the DApp

Before beginning the interaction, declare the variables that we will be using. So first, go to a separate terminal window and execute the commands below to initialize the variables.

> [!IMPORTANT]
> The values used through this interaction consider that the example is running locally. The contracts addresses can be found in the `deployments`.

> [!IMPORTANT]
> If running in testnet, remember to transfer some [LINK](https://faucets.chain.link/) tokens to the TrustAndTeach contract so it can pay the randomness generated by the Chainlink network.

```shell
export PLAYER1="0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266"
export PLAYER1_PRIVATE_KEY="0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80"
export PLAYER2="0x70997970C51812dc3A010C7d01b50e0d17dc79C8"
export PLAYER2_PRIVATE_KEY="0x59c6995e998f97a5a0044966f0945389dc9e86dae88c7a8412f4603b6b78690d"
export TRUST_AND_TEACH="0x959922bE3CAee4b8Cd9a407cc3ac1C251C2007B1"
export DAPP_ADDRESS="0x70ac08179605AF2D9e75782b8DEcDD3c22aA4D0C"
export RPC_URL="http://localhost:8545"
```

> [!NOTE]
> The image `ghcr.io/foundry-rs/foundry` its from [Foundry](https://book.getfoundry.sh/getting-started/installation) and allow us to use the [cast](https://book.getfoundry.sh/reference/cast/cast) command to send transactions.

1. Execute the `set_dapp_address` method of the `trust-and-teach` contract to set the rollup contract address. This step is to allow the layer-1 contract to send inputs to the Cartesi Rollups DApp.

```shell
docker run --rm --net="host" ghcr.io/foundry-rs/foundry "cast send --private-key $PLAYER1_PRIVATE_KEY --rpc-url $RPC_URL $TRUST_AND_TEACH \"set_dapp_address(address)\" $DAPP_ADDRESS"
```

2. Execute the `play` method passing the opponent's address to challenge him for a coin toss game.

```shell
docker run --rm --net="host" ghcr.io/foundry-rs/foundry "cast send --private-key $PLAYER1_PRIVATE_KEY --rpc-url $RPC_URL $TRUST_AND_TEACH \"play(address)\" $PLAYER2"
```

3. The challenged player executes the same `play` method passing the challenger address. The input is then fetched by the Cartesi Node the coin toss is executed inside the Cartesi Machine. A notice and a voucher are generated.

```shell
docker run --rm --net="host" ghcr.io/foundry-rs/foundry "cast send --private-key $PLAYER2_PRIVATE_KEY --rpc-url $RPC_URL $TRUST_AND_TEACH \"play(address)\" $PLAYER1"
```

4. (Optional) Check the notice and the voucher using the [frontend-console](https://github.com/cartesi/rollups-examples/tree/main/frontend-console).
5. Wait for the dispute period to end to execute the voucher. The dispute period is set to 5 minutes in testnet^, as can be seen in `docker-compose-testnet.yml`. If running locally advance the time with the following command:

```shell
curl --data '{"id":1337,"jsonrpc":"2.0","method":"evm_increaseTime","params":[864010]}' http://localhost:8545
```

6. Execute the voucher using the `frontend-console`.
```shell
yarn start voucher execute --index 0 --input 0
```

7. Check the value of the `last_game` variable in the `TrustAndTeach` smart contract to see the persisted result in layer-1 due to the voucher execution.

```shell
docker run --rm --net="host" ghcr.io/foundry-rs/foundry "cast call --rpc-url $RPC_URL ${TRUST_AND_TEACH} \"last_game()\""
```

^ **The value was chosen for testing purposes, do not use it in production!!!** The default value is 1 week.
